{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e65ad-c659-44aa-961a-a5f1559eab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2025 Chase Holdener\n",
    "# Licensed under the MIT License. See LICENSE file for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39274d5-8a97-4785-a150-dc08728206a8",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87163f-9721-4fce-ae21-40e89fb713f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import External Required Packages\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "### Import Smoothie Functions\n",
    "sys.path.append('/path/to/Smoothie/src/') # Make this the path to the Smoothie src directory!\n",
    "from gaussian_smoothing import *\n",
    "from spatial_correlation import *\n",
    "from network_analysis import *\n",
    "from multi_sample_integration import *\n",
    "from plotting import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4555c381-e425-40c7-8f9c-12b3d320e130",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a74c96-35f7-49b1-ac18-075d74c5afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in anndata structures (raw count matrix)\n",
    "adata_1 = ad.read_h5ad(\"/location/of/adata_1.h5ad\")\n",
    "adata_2 = ad.read_h5ad(\"/location/of/adata_2.h5ad\")\n",
    "adata_3 = ad.read_h5ad(\"/location/of/adata_3.h5ad\")\n",
    "adata_4 = ad.read_h5ad(\"/location/of/adata_4.h5ad\")\n",
    "# ... however many datasets you have!\n",
    "\n",
    "## Or, build your own anndata stuctures with a sparse count matrix, spatial coordinates 2D arr, and gene names 1D arr!\n",
    "##   Cells/spots are rows, genes are columns (info:  https://anndata.dynverse.org/reference/AnnData.html)\n",
    "# adata_1 = ad.AnnData(my_csr_sparse_count_matrix) # N rows (spots), G columns (genes)\n",
    "# adata_1.obsm['spatial'] = my_spatial_coordinates_2Darr # N rows (spots), 2 columns (x,y values)\n",
    "# adata_1.var_names = my_gene_names_1Darr # length G arr (gene names for each column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda29bb5-53be-41dd-9d53-3fac24f7ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a list of all anndata structures\n",
    "adata_set = [adata_1, adata_2, adata_3, adata_4] # ... however many datasets you have!\n",
    "\n",
    "## Make a list of names for each anndata structure\n",
    "adata_set_names = ['name1', 'name2', 'name3', 'name4'] # ... however many datasets you have!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc84e4-0c94-4f8b-8261-92e84591738c",
   "metadata": {},
   "source": [
    "## Quality Control + Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2d606-e3fb-4709-a222-125fb1f7a677",
   "metadata": {},
   "source": [
    "#### QC filtering depends on the spatial transcriptomics platform and its spatial resolution\n",
    "\n",
    "#### Slide-seq (10 micron resolution spots): \n",
    "- SPOT_UMI_THRESHOLD [10-200]\n",
    "- GENE_UMI_THRESHOLD [100-500]\n",
    "\n",
    "#### Binned Stereo-seq (20-50 micron resolution spots):\n",
    "- SPOT_UMI_THRESHOLD [50-500]\n",
    "- GENE_UMI_THRESHOLD [100-500]\n",
    "\n",
    "#### Unbinned Stereo-seq (0.5 micron resolution spots):\n",
    "- SPOT_UMI_THRESHOLD [1-2] **\n",
    "- GENE_UMI_THRESHOLD [100-500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196fff1-d0fc-4e26-a5e2-bec3eb863ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply QC to each dataset\n",
    "for i in range(len(adata_set)):\n",
    "\n",
    "    # Keep SPOTS that have at least SPOT_UMI_THRESHOLD counts across all genes\n",
    "    SPOT_UMI_THRESHOLD = 50\n",
    "    adata_set[i].obs['total_raw_spotcounts'] = np.sum(adata_set[i].X, axis = 1)\n",
    "    adata_set[i] = adata_set[i][adata_set[i].obs['total_raw_spotcounts'] >= SPOT_UMI_THRESHOLD, :]\n",
    "\n",
    "    # Keep GENES that have at least GENE_UMI_THRESHOLD counts tissue-wide\n",
    "    GENE_UMI_THRESHOLD = 100 # (Aim low here! Smoothie does gene feature selection later.)\n",
    "    adata_set[i].var['total_raw_counts'] = np.array(np.sum(adata_set[i].X, axis=0))[0]\n",
    "    adata_set[i] = adata_set[i][:, adata_set[i].var['total_raw_counts'] >= GENE_UMI_THRESHOLD]\n",
    "    \n",
    "    # Other QC filters may be included"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa870390-70f7-4ae5-a985-2d4e453e6a1d",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82104217-cf81-47af-9ef4-50aae8a89f8e",
   "metadata": {},
   "source": [
    "#### Choose Normalization \n",
    "1. CPT + log1p normalization (DEFAULT)\n",
    "2. log1p normalization only (For unbinned sub-micron resolution data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5354177-c0d0-4b46-97ba-826f332d05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply chosen normalization to each dataset\n",
    "for i in range(len(adata_set)):\n",
    "\n",
    "    ## CPT + Log1p normalization\n",
    "    TARGET_SUM = 1e3\n",
    "    sc.pp.normalize_total(adata_set[i], target_sum=TARGET_SUM)\n",
    "    sc.pp.log1p(adata_set[i])\n",
    "    adata_set[i].var['norm_total_counts'] = np.array(np.sum(adata_set[i].X, axis=0))[0]\n",
    "    \n",
    "    # ## Log1p normalization only (For unbinned sub-micron resolution data)\n",
    "    # sc.pp.log1p(adata_set[i])\n",
    "    # adata_set[i].var['norm_total_counts'] = np.array(np.sum(adata_set[i].X, axis=0))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20adf4fe-2271-4e36-88ff-eba6193ad660",
   "metadata": {},
   "source": [
    "## Run Gaussian smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56675630-8f27-465d-a592-3878b97d4f35",
   "metadata": {},
   "source": [
    "#### Notable Parameters:\n",
    "#### grid_based_or_not : bool\n",
    "- True = grid-based smoothing, smooth only at imposed hexagonal grid points, good for subcellular resolution data (0.5-2 micron).\n",
    "- False = in-place smoothing, smooth at every spatial location in the dataset, good for \"cell-sized\" resolution data (10-50 micron).\n",
    "\n",
    "#### gaussian_sd : float\n",
    "- Standard deviation for the Gaussian kernel. Carefully choose this variable based on S.T. data platform.\n",
    "- For Slide-seq, a value of 46.37 - 61.82 (30um - 40um) is appropriate.\n",
    "- For Stereo-seq sub-micron spots, a value of 40 - 60 (20um to 30um) is appropriate.\n",
    "- Generally across high-resolution S.T. platforms, the range 20-40um is likely ideal.\n",
    "- Note: Each S.T. data platform has a different conversion factor from their coordinate units to micrometers.\n",
    "\n",
    "#### min_spots_under_gaussian : int\n",
    "- Minimum number of data points within radius (3 * gaussian_sd) of center point for smoothing to occur at that location\n",
    "- (default is 25-100).\n",
    "\n",
    "#### stride : float, optional\n",
    "- Stride value for grid-based smoothing (default stride = 1 * gaussian_sd). \n",
    "- (0.5 * gaussian_sd is reasonable too for a denser grid).\n",
    "\n",
    "#### (Check src code for full parameter list).\n",
    "\n",
    "#### Returns:\n",
    "#### sm_adata : AnnData\n",
    "- The smoothed AnnData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71359509-d4de-49a5-89f0-b7c5acdcc239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list for smoothed adatas\n",
    "sm_adata_set = []\n",
    "\n",
    "## CHOOSE In-place smoothing OR Grid-based smoothing\n",
    "\n",
    "# In-place smoothing (Slide-seq 10um resolution default parameters)\n",
    "for adata in adata_set:\n",
    "    sm_adata_set.append(\n",
    "        run_parallelized_smoothing(adata,\n",
    "                                   grid_based_or_not=False,\n",
    "                                   gaussian_sd=46.37, # ADJUST AS NEEDED (46.37 corresponds to 30 microns for Slide-seq)\n",
    "                                   min_spots_under_gaussian=25)\n",
    "    )\n",
    "\n",
    "# # Grid-based smoothing (Stereo-seq 0.5um resolution default parameters)\n",
    "# for adata in adata_set:\n",
    "#     sm_adata_set.append(\n",
    "#         run_parallelized_smoothing(adata,\n",
    "#                                    grid_based_or_not=True,\n",
    "#                                    gaussian_sd=40, # ADJUST AS NEEDED (40 corresponds to 20 microns for Stereo-seq)\n",
    "#                                    min_spots_under_gaussian=100)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20d36e-f5f1-49f8-b8ae-70a95e18190b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Checkpoint for saving/loading smoothed adatas\n",
    "\n",
    "output_folder = '/location/of/save/folder'\n",
    "\n",
    "# Save smoothed anndatas\n",
    "for i, sm_adata in enumerate(sm_adata_set):\n",
    "    sm_adata.write_h5ad(f\"{output_folder}/sm_adata_{adata_set_names[i]}.h5ad\")\n",
    "\n",
    "\n",
    "# # Load in smoothed anndata structures\n",
    "# sm_adata_1 = ad.read_h5ad(\"./output_folder/sm_adata_1.h5ad\")\n",
    "# sm_adata_2 = ad.read_h5ad(\"./output_folder/sm_adata_2.h5ad\")\n",
    "# sm_adata_3 = ad.read_h5ad(\"./output_folder/sm_adata_3.h5ad\")\n",
    "# sm_adata_4 = ad.read_h5ad(\"./output_folder/sm_adata_4.h5ad\")\n",
    "# ... however many datasets you have!\n",
    "\n",
    "# adata_set_names = ['name1', 'name2', 'name3', 'name4'] # ... however many datasets you have!\n",
    "# sm_adata_set = [sm_adata_1, sm_adata_2, sm_adata_3, sm_adata_4] # ... however many datasets you have!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b713ec21-9842-4c4f-a226-e4a66a6b0891",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Run Smoothing on Shuffled Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f220bf-894b-4cf5-bff5-9d5c3de84752",
   "metadata": {},
   "source": [
    "Here, we generate spatially shuffled versions of the dataset, apply smoothing, and compute the 95th, 99th, and 99.9th percentiles of the highest Pearson correlation coefficients. \n",
    "\n",
    "These percentiles, derived under the random null hypothesis, serve as thresholds for selecting a PCC cutoff for network construction in the real (unshuffled) dataset.\n",
    "\n",
    "For large count matrices, you may need to use the save/load checkpoints and then clear memory to prevent having adata_set, sm_adata_set, sh_adata_set, and sm_sh_adata_set all loaded simultaneously!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cbb14f-84e3-47d1-bc33-58cc5e4ebea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a shuffled version of each adata\n",
    "sh_adata_set = []\n",
    "\n",
    "# Shuffling of all coordinates (For 10-50 micron resolution data)\n",
    "for adata in adata_set:\n",
    "    sh_adata = adata.copy()\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(sh_adata.obsm['spatial'])\n",
    "    sh_adata_set.append(sh_adata)\n",
    "\n",
    "# # Bin-shuffling (For sub-micron resolution data)\n",
    "# for adata in adata_set:\n",
    "    # sh_adata = adata.copy()\n",
    "    # bin_shuffle_adata(sh_adata, bin_width=40, seed=0) # 40 corresponds to 20 micron width bins for Stereo-seq\n",
    "    # sh_adata_set.append(sh_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25729875-319d-46cb-a91d-bea23953d99d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Checkpoint for saving/loading shuffled adatas\n",
    "\n",
    "output_folder = '/location/of/save/folder'\n",
    "\n",
    "# Save shuffled anndatas\n",
    "for i, sh_adata in enumerate(sh_adata_set):\n",
    "    sh_adata.write_h5ad(f\"{output_folder}/sh_adata_{adata_set_names[i]}.h5ad\")\n",
    "\n",
    "\n",
    "# # Load in shuffled anndata structures\n",
    "# sh_adata_1 = ad.read_h5ad(\"./output_folder/sh_adata_1.h5ad\")\n",
    "# sh_adata_2 = ad.read_h5ad(\"./output_folder/sh_adata_2.h5ad\")\n",
    "# sh_adata_3 = ad.read_h5ad(\"./output_folder/sh_adata_3.h5ad\")\n",
    "# sh_adata_4 = ad.read_h5ad(\"./output_folder/sh_adata_4.h5ad\")\n",
    "# ... however many datasets you have!\n",
    "\n",
    "# adata_set_names = ['name1', 'name2', 'name3', 'name4'] # ... however many datasets you have!\n",
    "# sh_adata_set = [sh_adata_1, sh_adata_2, sh_adata_3, sh_adata_4] # ... however many datasets you have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b6380-c15e-4392-8788-632439404fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a smoothed, shuffled version of each adata\n",
    "sm_sh_adata_set = []\n",
    "\n",
    "## CHOOSE In-place smoothing OR Grid-based smoothing\n",
    "# Use identical smoothing parameters as you did on the true dataset above\n",
    "\n",
    "# In-place smoothing (Slide-seq 10um resolution default parameters)\n",
    "for sh_adata in sh_adata_set:\n",
    "    sm_sh_adata_set.append(\n",
    "        run_parallelized_smoothing(sh_adata,\n",
    "                                   grid_based_or_not=False,\n",
    "                                   gaussian_sd=46.37, # (46.37 corresponds to 30 microns for Slide-seq)\n",
    "                                   min_spots_under_gaussian=25)\n",
    "    )\n",
    "\n",
    "# # Grid-based smoothing (Stereo-seq 0.5um resolution default parameters)\n",
    "# for sh_adata in sh_adata_set:\n",
    "#     sm_sh_adata_set.append(\n",
    "#         run_parallelized_smoothing(sh_adata,\n",
    "#                                    grid_based_or_not=True,\n",
    "#                                    gaussian_sd=40, # (40 corresponds to 20 microns for Stereo-seq)\n",
    "#                                    min_spots_under_gaussian=100)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fe12e3-b79e-4e02-95c4-370edff27436",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Checkpoint for saving/loading smoothed, shuffled adatas\n",
    "\n",
    "output_folder = '/location/of/save/folder'\n",
    "\n",
    "# Save smoothed shuffled anndatas\n",
    "for i, sm_sh_adata in enumerate(sm_sh_adata_set):\n",
    "    sm_sh_adata.write_h5ad(f\"{output_folder}/sm_sh_adata_{adata_set_names[i]}.h5ad\")\n",
    "\n",
    "\n",
    "# # Load in smoothed shuffled anndata structures\n",
    "# sm_sh_adata_1 = ad.read_h5ad(\"./output_folder/sm_sh_adata_1.h5ad\")\n",
    "# sm_sh_adata_2 = ad.read_h5ad(\"./output_folder/sm_sh_adata_2.h5ad\")\n",
    "# sm_sh_adata_3 = ad.read_h5ad(\"./output_folder/sm_sh_adata_3.h5ad\")\n",
    "# sm_sh_adata_4 = ad.read_h5ad(\"./output_folder/sm_sh_adata_4.h5ad\")\n",
    "# ... however many datasets you have!\n",
    "\n",
    "# adata_set_names = ['name1', 'name2', 'name3', 'name4'] # ... however many datasets you have!\n",
    "# sm_adata_set = [sm_sh_adata_1, sm_sh_adata_2, sm_sh_adata_3, sm_sh_adata_4] # ... however many datasets you have!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878af53e-fe5e-48d3-8dd5-842694d1a319",
   "metadata": {},
   "source": [
    "## Find Gene Modules Across Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4196ba-88d5-46f6-af68-b1f263799b51",
   "metadata": {},
   "source": [
    "#### Here, we concatenate the smoothed count matrices and then calculate pairwise gene correlations using the concatenated matrix. The correlation matrix is used for network construction and clustering to identify gene modules across datasets.\n",
    "\n",
    "This step approximately doubles the memory requirement of sm_adata_set and sm_sh_adata_set. For large count matrices, you may need clear memory between running the analysis on sm_adata_set and sm_sh_adata_set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607c4bfb-325c-4de1-85c7-7353556e98bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a concatenated smoothed count matrix X_concat, with gene names for each column\n",
    "sm_adata_X_concat, sm_adata_X_concat_gene_names = concatenate_smoothed_matrices(sm_adata_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89404ab-96ce-41cc-976d-e3cfd116511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Pearson correlation matrix (This step can take a while... depending on sm_adata_X_concat size)\n",
    "pearsonR_mat_concat, pVal_mat_concat = compute_correlation_matrix(sm_adata_X_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86774352-2730-4911-8f7b-f0651b5ea126",
   "metadata": {},
   "source": [
    "#### Constructing the Network\n",
    "#### Notable Parameters:\n",
    "#### pcc_cutoff : float (in interval (0,1))\n",
    "- The Pearson correlation coefficient (PCC) hard threshold for network construction.\n",
    "- Only correlations above this value are retained in the network.\n",
    "- The pcc_cutoff should be higher than the upper 95th-99.9th percentile of pairwise PCC values generated from the smoothed spatially shuffled count matrix. (pcc_cutoff=0.4 (+/- 0.1) is usually an effective choice.)\n",
    "* Higher values result in smaller, stronger average correlation networks.\n",
    "* Lower values result in larger, weaker average correlation networks.\n",
    "\n",
    "#### clustering_power : float (greater than 1)\n",
    "- A soft thresholding parameter that controls the rescaling of Pearson correlation values. Defaults to 4 if None.\n",
    "- Prior to soft thresholding, correlation values are linearly rescaled from interval (pcc_cutoff, 1) to (0,1).\n",
    "* Higher values result in more modular networks.\n",
    "\n",
    "#### gene_labels_list : list of list/tuple/np.ndarray, optional\n",
    "- A list containing gene set labels. Each item in the list should have the same length as the number of genes.\n",
    "- This is useful if you'd like to add gene information to the network for visualization.\n",
    "\n",
    "#### gene_labels_names : list, optional\n",
    "- A list of names, with each name corresponding to a gene set in `gene_labels_list`.\n",
    "\n",
    "#### (Check src code for full parameter list).\n",
    "\n",
    "#### Returns:\n",
    "#### edge_list : list\n",
    "- List of edges in the format [gene1, gene2, PCC, Rescaled_PCC].\n",
    "- May be imported as network into Cytoscape for visualization!\n",
    "\n",
    "#### node_label_df : pd.DataFrame\n",
    "- DataFrame with gene names, community labels, and various network metrics.\n",
    "- May be imported as node table into Cytoscape for visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222db2e-934b-4575-a0e6-2fd95cc338fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list, node_label_df = make_spatial_network(pearsonR_mat_concat,\n",
    "                                                gene_names=sm_adata_X_concat_gene_names,\n",
    "                                                pcc_cutoff=0.4,\n",
    "                                                clustering_power=4,\n",
    "                                                gene_labels_list=None,\n",
    "                                                gene_labels_names=None,\n",
    "                                                output_folder=\"/location/of/save/folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74681224-d994-45a6-8687-1bc227ef554b",
   "metadata": {},
   "source": [
    "#### Spatial Plotting Genes/Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3270cd5-1425-4904-804f-7c1437f8545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SINGLE GENE expression across datasets\n",
    "#   full documentation in Smoothie/src/plotting.py\n",
    "\n",
    "plot_gene_multisample(\n",
    "    sm_adata_set, \n",
    "    adata_set_names, \n",
    "    gene_name='MyGene1', \n",
    "    output_folder='/location/of/save/folder', \n",
    "    shared_scaling=False, # dataset independent or shared 0-to-max gene scaling for plotting\n",
    "    spot_size=25) # adjust spot_size to find optimal plotting resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b97259-d185-4207-9961-7c611d7e715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTRUCT GENE PATTERN ATLAS - Plot all module scores across datasets\n",
    "#   full documentation in Smoothie/src/plotting.py\n",
    "\n",
    "plot_modules_multisample(\n",
    "    sm_adata_set, \n",
    "    adata_set_names, \n",
    "    node_label_df,\n",
    "    output_folder='/location/of/save/folder',\n",
    "    shared_scaling=False, # dataset independent or shared 0-to-max module scaling for plotting\n",
    "    min_genes=3, # minimum number of genes in a module to plot the module (Use 2 or 3).\n",
    "    spot_size=25) # adjust spot_size to find optimal plotting resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8c64c3-66c3-4566-9118-6740512b346e",
   "metadata": {},
   "source": [
    "#### Find Top Correlations of a Gene of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4764d1-bd50-44c7-ba65-4485999a9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top correlations or top anti-correlations to a gene of interest\n",
    "#  (full documentation in Smoothie/src/spatial_correlation.py)\n",
    "\n",
    "GOI_correlations = get_correlations_to_GOI(pearsonR_mat_concat, \n",
    "                                           gene_names=sm_adata_X_concat_gene_names, \n",
    "                                           GOI=\"myGene1\", # choose gene\n",
    "                                           reverse_order=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d99cb5-0034-4a50-90f0-c8478cbd8b3c",
   "metadata": {},
   "source": [
    "#### Make Network for a Subset of Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5f3a2-7690-43f0-b1ab-c1d7fb67b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a network for a gene set of interest--a targeted approach--using \n",
    "# a more permissive pcc cutoff for higher geneset member retention.\n",
    "#  (full documentation in Smoothie/src/network_analysis.py)\n",
    "\n",
    "myGeneList = ['gene1', 'gene2', 'gene3']\n",
    "\n",
    "geneset_edge_list, geneset_node_label_df = make_geneset_spatial_network(\n",
    "    pearsonR_mat_concat,\n",
    "    gene_names=sm_adata_X_concat_gene_names,\n",
    "    node_label_df=node_label_df,\n",
    "    gene_list=myGeneList,\n",
    "    low_pcc_cutoff=0.2, # choose low_pcc_cutoff <= pcc_cutoff (from above)\n",
    "    output_folder='/location/of/save/folder',\n",
    "    intra_geneset_edges_only=True, # exclude edges between geneset and non-geneset members?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7b3c6-2ac2-45c9-9a41-6fbce717b17b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Shuffled Data Gene Correlations (for PCC Cutoff Selection Above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec9b81-9573-4e34-b20d-7af931f420f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a concatenated smoothed shuffled count matrix X_concat, with gene names for each column\n",
    "sm_sh_adata_X_concat, sm_sh_adata_X_concat_gene_names = concatenate_smoothed_matrices(sm_sh_adata_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846a138-1e61-4d63-b866-0395fb9b077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Pearson correlation matrix and find 95%, 99%, and 99.9% value of correlation distribution\n",
    "pearsonR_mat_concat_sh, pVal_mat_concat_sh = compute_correlation_matrix(sm_sh_adata_X_concat)\n",
    "\n",
    "# Get the indices of the lower triangle of the matrix\n",
    "lower_tri_indices = np.tril_indices(pearsonR_mat_concat_sh.shape[0], -1)\n",
    "\n",
    "# True Data distribution\n",
    "shuf_lower_tri_values = pearsonR_mat_concat_sh[lower_tri_indices]\n",
    "print(f'95th PCC percentile for concatenated shuffled data: {np.percentile(shuf_lower_tri_values, 95)}')\n",
    "print(f'99th PCC percentile for concatenated shuffled data: {np.percentile(shuf_lower_tri_values, 99)}')\n",
    "print(f'99.9th PCC percentile for concatenated shuffled data: {np.percentile(shuf_lower_tri_values, 99.9)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db7b88-c0ab-4456-be5d-cf08f8615963",
   "metadata": {},
   "source": [
    "## Compare Gene Patterns Between Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ed631-257c-4c16-8d46-e3a7d5711e89",
   "metadata": {},
   "source": [
    "#### Here we take a second-order correlation approach to measure pattern similarity of genes between different datasets. \n",
    "The second-order correlation approach first involves filtering and aligning gene columns of the different dataset's correlation matrices. We then compare gene A in dataset 1 with gene B in dataset 2 by finding the correlation of row A in correlation matrix 1 with row B in correlation matrix 2. More details are included in the manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123586b0-3a4c-436c-ad76-bd6ac8651b45",
   "metadata": {},
   "source": [
    "#### First, compute correlation matrices for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6fe58-ec9e-4115-838e-f1cb1b8a99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonR_mat_set = []\n",
    "for sm_adata in sm_adata_set:\n",
    "    pearsonR_mat_curr, _ = compute_correlation_matrix(sm_adata.X)\n",
    "    pearsonR_mat_set.append(pearsonR_mat_curr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076fb98-5c4a-407f-9399-2bc1fec0531a",
   "metadata": {},
   "source": [
    "#### Next, align correlation matrices\n",
    "This ensures that that row i and col i correspond to the same gene for all matrices. (full documentation in Smoothie/src/multi_sample_integration.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7dfdee-f0ea-45b7-b9c6-29bfcf2193c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_pearsonR_tensor = align_gene_correlation_matrices(sm_adata_set, pearsonR_mat_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc12ba-b3c0-4da3-95a6-11b7fe98bdb0",
   "metadata": {},
   "source": [
    "#### Next, create gene embeddings for each gene in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c47a4c9-41a1-41d7-bb5e-0316ac4a942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function create_gene_embeddings returns two outputs:\n",
    "\n",
    "    gene_embeddings_tensor (np.ndarray): A 3D tensor with the following dimensions:  \n",
    "        Axis 0: Gene embedding vectors for comparison.  \n",
    "        Axis 1: Embedding features comprising the vectors.  \n",
    "        Axis 2: Spatial datasets, in the same order as `sm_adata_set`.\n",
    "        - A slice along axis 2 contains the gene embeddings for that dataset.\n",
    "        \n",
    "    robust_gene_names (np.ndarray): \n",
    "        An array of gene names corresponding to the axis 0 (embedding vectors) of `gene_embeddings_tensor`.  \n",
    "\n",
    "(full documentation in Smoothie/src/multi_sample_integration.py)\n",
    "\"\"\"\n",
    "\n",
    "gene_embeddings_tensor, robust_gene_names = create_gene_embeddings(\n",
    "    aligned_pearsonR_tensor, \n",
    "    sm_adata_set, \n",
    "    pcc_cutoff=0.4, # determine using each shuffled dataset's correlation matrix upper percentiles\n",
    "    node_label_df=node_label_df, # the dataframe from above containing multi-dataset gene module assignments\n",
    "    E_max=25, # maximum number of embedding features allowed within each gene module\n",
    "    seed=0 # random seed for feature downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b54888-9dea-467e-98e9-1770df7eeaa6",
   "metadata": {},
   "source": [
    "#### Next, find gene pattern stabilities across datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9ac3f-924e-4870-9371-6f8034c69a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function get_gene_stabilities_across_datasets returns: \n",
    "\n",
    "    gene_stabilities_across_datasets (np.ndarray): A 3D tensor with the following dimensions:\n",
    "        Axis 0: Spatial datasets, in the same order as `sm_adata_set`.\n",
    "        Axis 1: Spatial datasets, in the same order as `sm_adata_set`.\n",
    "        Axis 2: Genes, in same order as robust_gene_names.\n",
    "    \n",
    "    The indexed value `gene_stabilities_across_datasets[i,j,k]` is the stability of gene\n",
    "    `robust_gene_names[k]` between dataset `sm_adata_set[i]` and dataset `sm_adata_set[j]`!\n",
    "\n",
    "(full documentation in Smoothie/src/multi_sample_integration.py)\n",
    "\"\"\"\n",
    "\n",
    "gene_stabilities_across_datasets = get_gene_stabilities_across_datasets(\n",
    "    gene_embeddings_tensor, \n",
    "    robust_gene_names, \n",
    "    sm_adata_set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bedfef3-b4f9-46e6-b28f-184ad807f106",
   "metadata": {},
   "source": [
    "#### Add 'gene_stabilities' column to node_label_df for dynamic gene modules analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc7260-2ef5-40ca-89c0-9cc53e3aacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each gene, add minimum gene pattern stabilities across dataset pairs to node_label_df\n",
    "# (for network visualization and dynamic gene module analysis)\n",
    "\n",
    "add_gene_stability_labels(node_label_df, gene_stabilities_across_datasets, robust_gene_names)\n",
    "node_label_df.to_csv('/path/to/save/node_label_df_wStabilities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b8883b-c801-453a-ab4a-02ea492bb996",
   "metadata": {},
   "source": [
    "#### Order gene patterns from most stable to most dynamic across datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01139aa-3ba1-4da7-a703-a8ef1a7928db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values from 'gene_stabilities'\n",
    "node_label_df_clean = node_label_df.dropna(subset=['gene_stabilities'])\n",
    "\n",
    "# Plot histogram of non-NaN 'gene_stabilities' values\n",
    "plt.hist(node_label_df_clean['gene_stabilities'], bins=30, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Gene Stabilities')\n",
    "plt.xlabel('Gene Stability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "## Sort the DataFrame by 'gene_stabilities'\n",
    "# Stable to Dynamic sorting\n",
    "sorted_df = node_label_df_clean.sort_values(by='gene_stabilities', ascending=False)\n",
    "# # Dynamic to Stable sorting\n",
    "# sorted_df = node_label_df_clean.sort_values(by='gene_stabilities', ascending=True)\n",
    "\n",
    "# Output as a 2D array of 'name' and 'gene_stabilities'\n",
    "sorted_array = sorted_df[['name', 'gene_stabilities']].values\n",
    "sorted_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a80e11-0118-44da-a94d-3f7637691a82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Shuffled Data Gene Correlations (for PCC Cutoff Selection Above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5315cf1-c813-4ecd-ad47-5900acf37bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix upper percentiles for each shuffled dataset\n",
    "\n",
    "for i, sm_sh_adata in enumerate(sm_sh_adata_set):\n",
    "    sh_pearsonR_mat_curr, _ = compute_correlation_matrix(sm_sh_adata.X)\n",
    "    \n",
    "    # Get the indices of the lower triangle of the matrix\n",
    "    lower_tri_indices = np.tril_indices(sh_pearsonR_mat_curr.shape[0], -1)\n",
    "    \n",
    "    # Shuffled Data distribution\n",
    "    shuf_lower_tri_values = sh_pearsonR_mat_curr[lower_tri_indices]\n",
    "    print(f'95th PCC percentile for shuffled {adata_set_names[i]} data: {np.percentile(shuf_lower_tri_values, 95)}')\n",
    "    print(f'99th PCC percentile for shuffled {adata_set_names[i]} data: {np.percentile(shuf_lower_tri_values, 99)}')\n",
    "    print(f'99.9th PCC percentile for shuffled {adata_set_names[i]} data: {np.percentile(shuf_lower_tri_values, 99.9)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b76da-7458-40a3-a7e4-3316e44ea77c",
   "metadata": {},
   "source": [
    "#### Plotting Gene Stabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b571152-46c3-4708-9103-ca155dec7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the stability of a given GOI across datasets\n",
    "\n",
    "## Parameters\n",
    "GOI = 'MyGene1'\n",
    "output_folder = '/location/of/save/folder'\n",
    "\n",
    "robust_gene_to_index = {gene: idx for idx, gene in enumerate(robust_gene_names)}\n",
    "goi_num = robust_gene_to_index[GOI]\n",
    "\n",
    "# create stability plot\n",
    "plt.figure(figsize=(1,1))\n",
    "img = plt.imshow(gene_stabilities_across_datasets[:,:,goi_num], \n",
    "           cmap='viridis', \n",
    "           interpolation='nearest',\n",
    "           vmin=-0.5,\n",
    "           vmax=1.0)\n",
    "plt.title(f'{GOI}', fontsize=6, pad=3)\n",
    "plt.grid(False)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(img, fraction=0.046, pad=0.05)\n",
    "cbar.ax.tick_params(labelsize=6)\n",
    "\n",
    "# modify axis labels\n",
    "plt.xticks(ticks = range(0,len(sm_adata_set)), labels = adata_set_names, fontsize=6, rotation=40, ha='right')\n",
    "#plt.xticks([]) # better for plotting!\n",
    "plt.yticks(ticks = range(0,len(sm_adata_set)), labels = adata_set_names, fontsize=6)\n",
    "plt.gca().tick_params(axis='x', labelsize=6, pad=1)\n",
    "plt.gca().tick_params(axis='y', labelsize=6, pad=1)\n",
    "\n",
    "# save plot\n",
    "pdf_filename = f'{output_folder}/{GOI}_stability_plot.pdf'\n",
    "plt.savefig(pdf_filename, format='pdf', bbox_inches='tight', dpi=900, pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "# Spatial plot for the GOI across all datasets\n",
    "#   full documentation in Smoothie/src/plotting.py\n",
    "plot_gene_multisample(sm_adata_set, \n",
    "                      adata_set_names, \n",
    "                      gene_name=GOI, \n",
    "                      output_folder=output_folder,\n",
    "                      shared_scaling=False, # dataset independent or shared 0-to-max gene scaling for plotting\n",
    "                      spot_size=25) # adjust spot_size to find optimal plotting resolution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
